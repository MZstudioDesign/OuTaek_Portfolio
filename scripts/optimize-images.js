/**
 * ========================================
 * Image Optimizer Script
 * ========================================
 * 
 * assets/images/portfolio í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ì›¹ ìµœì í™”
 * - PNG/JPG â†’ WebP ë³€í™˜
 * - ìµœëŒ€ ê°€ë¡œ 1920px ë¦¬ì‚¬ì´ì¦ˆ
 * - í’ˆì§ˆ 80% ì••ì¶•
 * 
 * ì‚¬ìš©ë²•: npm run optimize-images
 * 
 * @module scripts/optimize-images
 */

const fs = require('fs');
const path = require('path');
const sharp = require('sharp');

const IMAGES_DIR = path.join(__dirname, '..', 'assets', 'images', 'portfolio');
const MAX_WIDTH = 1920;
const QUALITY = 80;

async function optimizeImages() {
    console.log('ğŸ–¼ï¸  Starting image optimization...\n');
    console.log(`ğŸ“‚ Directory: ${IMAGES_DIR}`);
    console.log(`ğŸ“ Max width: ${MAX_WIDTH}px`);
    console.log(`ğŸ¨ Quality: ${QUALITY}%\n`);

    if (!fs.existsSync(IMAGES_DIR)) {
        console.error('âŒ Directory not found:', IMAGES_DIR);
        process.exit(1);
    }

    const files = fs.readdirSync(IMAGES_DIR);
    // Exclude GIFs from optimization
    const imageFiles = files.filter(f => /\.(png|jpg|jpeg)$/i.test(f));
    const skippedGifs = files.filter(f => /\.gif$/i.test(f)).length;

    console.log(`ğŸ“Š Found ${imageFiles.length} images to optimize (skipped ${skippedGifs} GIFs)\n`);

    let totalOriginal = 0;
    let totalOptimized = 0;
    let processed = 0;
    let skipped = 0;

    for (const file of imageFiles) {
        const inputPath = path.join(IMAGES_DIR, file);
        const baseName = path.parse(file).name;
        const outputPath = path.join(IMAGES_DIR, `${baseName}.webp`);

        // Skip if WebP already exists and is newer
        if (fs.existsSync(outputPath)) {
            const inputStat = fs.statSync(inputPath);
            const outputStat = fs.statSync(outputPath);
            if (outputStat.mtime > inputStat.mtime) {
                skipped++;
                continue;
            }
        }

        try {
            const inputStat = fs.statSync(inputPath);
            const originalSize = inputStat.size;
            totalOriginal += originalSize;

            // Get image metadata
            const metadata = await sharp(inputPath).metadata();

            // Resize if wider than MAX_WIDTH
            let pipeline = sharp(inputPath);
            if (metadata.width > MAX_WIDTH) {
                pipeline = pipeline.resize(MAX_WIDTH, null, { withoutEnlargement: true });
            }

            // Convert to WebP
            await pipeline
                .webp({ quality: QUALITY })
                .toFile(outputPath);

            const outputStat = fs.statSync(outputPath);
            const optimizedSize = outputStat.size;
            totalOptimized += optimizedSize;

            const reduction = ((1 - optimizedSize / originalSize) * 100).toFixed(1);
            const originalKB = (originalSize / 1024).toFixed(0);
            const optimizedKB = (optimizedSize / 1024).toFixed(0);

            console.log(`âœ… ${file} â†’ ${baseName}.webp (${originalKB}KB â†’ ${optimizedKB}KB, -${reduction}%)`);

            // Delete original after successful conversion
            fs.unlinkSync(inputPath);
            processed++;

        } catch (err) {
            console.error(`âŒ Failed: ${file} - ${err.message}`);
        }
    }

    const totalOriginalMB = (totalOriginal / 1024 / 1024).toFixed(2);
    const totalOptimizedMB = (totalOptimized / 1024 / 1024).toFixed(2);
    const totalReduction = totalOriginal > 0
        ? ((1 - totalOptimized / totalOriginal) * 100).toFixed(1)
        : 0;

    console.log('\n' + 'â•'.repeat(50));
    console.log('âœ¨ Optimization complete!');
    console.log(`   ğŸ“Š Processed: ${processed}`);
    console.log(`   â­ï¸  Skipped: ${skipped}`);
    console.log(`   ğŸ“¦ Before: ${totalOriginalMB} MB`);
    console.log(`   ğŸ“¦ After: ${totalOptimizedMB} MB`);
    console.log(`   ğŸ’¾ Saved: ${totalReduction}%`);
    console.log('â•'.repeat(50));
}

optimizeImages().catch(err => {
    console.error('âŒ Optimization failed:', err.message);
    process.exit(1);
});
